/**
 * @fileoverview é‡å¤æ–‡ä»¶æ£€æµ‹å™¨
 * @description æ£€æµ‹å’Œç®¡ç†é‡å¤æ–‡ä»¶ï¼ŒåŸºäºå“ˆå¸Œå€¼è¿›è¡Œå»é‡
 */

import { prisma } from '@/lib/prisma';
import { HashCalculator } from './hash-calculator';

export interface DuplicateFile {
  id: string;
  hash: string;
  url: string;
  filename: string;
  fileSize: number;
  uploadCount: number;
}

export interface DeduplicationResult {
  isDuplicate: boolean;
  existingFile?: DuplicateFile;
  shouldUpload: boolean;
}

/**
 * é‡å¤æ–‡ä»¶æ£€æµ‹å™¨ç±»
 */
export class DuplicateDetector {
  /**
   * æŸ¥æ‰¾é‡å¤æ–‡ä»¶ï¼ˆåŸºäºå“ˆå¸Œå€¼ï¼‰
   */
  public static async findDuplicateFile(fileHash: string): Promise<DuplicateFile | null> {
    if (!fileHash || !HashCalculator.isValidHash(fileHash)) {
      return null;
    }

    try {
      const existingFile = await prisma.fileHash.findUnique({
        where: { hash: fileHash },
      });

      if (existingFile) {
        return {
          id: existingFile.id,
          hash: existingFile.hash,
          url: existingFile.url,
          filename: existingFile.filename,
          fileSize: existingFile.fileSize,
          uploadCount: existingFile.uploadCount,
        };
      }

      return null;
    } catch (error) {
      console.error('æŸ¥æ‰¾é‡å¤æ–‡ä»¶æ—¶å‡ºé”™:', error);
      return null;
    }
  }

  /**
   * æ£€æŸ¥æ–‡ä»¶æ˜¯å¦é‡å¤
   */
  public static async checkDeduplication(
    fileHash: string,
    options: {
      enableDeduplication?: boolean;
      updateUploadCount?: boolean;
    } = {}
  ): Promise<DeduplicationResult> {
    const { enableDeduplication = true, updateUploadCount = true } = options;

    if (!enableDeduplication) {
      return {
        isDuplicate: false,
        shouldUpload: true,
      };
    }

    try {
      const existingFile = await this.findDuplicateFile(fileHash);

      if (existingFile) {
        // æ›´æ–°ä¸Šä¼ æ¬¡æ•°
        if (updateUploadCount) {
          await this.incrementUploadCount(fileHash);
        }

        console.log(`ğŸ”„ å‘ç°é‡å¤æ–‡ä»¶: ${existingFile.filename} (ä¸Šä¼ æ¬¡æ•°: ${existingFile.uploadCount + 1})`);

        return {
          isDuplicate: true,
          existingFile: {
            ...existingFile,
            uploadCount: existingFile.uploadCount + (updateUploadCount ? 1 : 0),
          },
          shouldUpload: false,
        };
      }

      return {
        isDuplicate: false,
        shouldUpload: true,
      };
    } catch (error) {
      console.error('æ£€æŸ¥æ–‡ä»¶å»é‡æ—¶å‡ºé”™:', error);
      // å‡ºé”™æ—¶å…è®¸ä¸Šä¼ ï¼Œé¿å…é˜»å¡ç”¨æˆ·
      return {
        isDuplicate: false,
        shouldUpload: true,
      };
    }
  }

  /**
   * å¢åŠ æ–‡ä»¶ä¸Šä¼ æ¬¡æ•°
   */
  public static async incrementUploadCount(fileHash: string): Promise<void> {
    try {
      await prisma.fileHash.update({
        where: { hash: fileHash },
        data: {
          uploadCount: { increment: 1 },
          lastUploadAt: new Date(),
        },
      });
    } catch (error) {
      console.error('æ›´æ–°ä¸Šä¼ æ¬¡æ•°æ—¶å‡ºé”™:', error);
      // ä¸æŠ›å‡ºé”™è¯¯ï¼Œé¿å…å½±å“ä¸»æµç¨‹
    }
  }

  /**
   * æ‰¹é‡æ£€æŸ¥å¤šä¸ªæ–‡ä»¶çš„é‡å¤çŠ¶æ€
   */
  public static async batchCheckDeduplication(
    fileHashes: string[]
  ): Promise<Map<string, DeduplicationResult>> {
    const results = new Map<string, DeduplicationResult>();

    if (fileHashes.length === 0) {
      return results;
    }

    try {
      // æ‰¹é‡æŸ¥è¯¢æ•°æ®åº“
      const existingFiles = await prisma.fileHash.findMany({
        where: {
          hash: { in: fileHashes },
        },
      });

      // åˆ›å»ºå“ˆå¸Œåˆ°æ–‡ä»¶çš„æ˜ å°„
      const hashToFileMap = new Map<string, DuplicateFile>();
      existingFiles.forEach(file => {
        hashToFileMap.set(file.hash, {
          id: file.id,
          hash: file.hash,
          url: file.url,
          filename: file.filename,
          fileSize: file.fileSize,
          uploadCount: file.uploadCount,
        });
      });

      // ä¸ºæ¯ä¸ªå“ˆå¸Œç”Ÿæˆç»“æœ
      fileHashes.forEach(hash => {
        const existingFile = hashToFileMap.get(hash);

        if (existingFile) {
          results.set(hash, {
            isDuplicate: true,
            existingFile,
            shouldUpload: false,
          });
        } else {
          results.set(hash, {
            isDuplicate: false,
            shouldUpload: true,
          });
        }
      });

      return results;
    } catch (error) {
      console.error('æ‰¹é‡æ£€æŸ¥å»é‡æ—¶å‡ºé”™:', error);

      // å‡ºé”™æ—¶ä¸ºæ‰€æœ‰æ–‡ä»¶è¿”å›å…è®¸ä¸Šä¼ çš„ç»“æœ
      fileHashes.forEach(hash => {
        results.set(hash, {
          isDuplicate: false,
          shouldUpload: true,
        });
      });

      return results;
    }
  }

  /**
   * è·å–é‡å¤æ–‡ä»¶åˆ—è¡¨
   */
  public static async getDuplicateFiles(options: {
    page?: number;
    limit?: number;
    sortBy?: 'uploadCount' | 'fileSize' | 'lastUploadAt';
    sortOrder?: 'asc' | 'desc';
    minUploadCount?: number;
  } = {}) {
    const {
      page = 1,
      limit = 20,
      sortBy = 'uploadCount',
      sortOrder = 'desc',
      minUploadCount = 2,
    } = options;

    try {
      const duplicateFiles = await prisma.fileHash.findMany({
        where: {
          uploadCount: { gte: minUploadCount },
        },
        orderBy: {
          [sortBy]: sortOrder,
        },
        skip: (page - 1) * limit,
        take: limit,
      });

      const total = await prisma.fileHash.count({
        where: {
          uploadCount: { gte: minUploadCount },
        },
      });

      return {
        files: duplicateFiles.map(file => ({
          id: file.id,
          hash: file.hash,
          url: file.url,
          filename: file.filename,
          fileSize: file.fileSize,
          uploadCount: file.uploadCount,
          lastUploadAt: file.lastUploadAt,
          savedSpace: file.fileSize * (file.uploadCount - 1),
        })),
        pagination: {
          page,
          limit,
          total,
          totalPages: Math.ceil(total / limit),
        },
      };
    } catch (error) {
      console.error('è·å–é‡å¤æ–‡ä»¶åˆ—è¡¨æ—¶å‡ºé”™:', error);
      return {
        files: [],
        pagination: {
          page: 1,
          limit: 20,
          total: 0,
          totalPages: 0,
        },
      };
    }
  }

  /**
   * åˆ é™¤é‡å¤æ–‡ä»¶è®°å½•
   */
  public static async removeDuplicateRecord(fileHash: string): Promise<boolean> {
    try {
      await prisma.fileHash.delete({
        where: { hash: fileHash },
      });

      console.log(`ğŸ—‘ï¸ åˆ é™¤é‡å¤æ–‡ä»¶è®°å½•: ${fileHash}`);
      return true;
    } catch (error) {
      console.error('åˆ é™¤é‡å¤æ–‡ä»¶è®°å½•æ—¶å‡ºé”™:', error);
      return false;
    }
  }

  /**
   * æ£€æµ‹åª’ä½“åˆ—è¡¨ä¸­çš„é‡å¤æ–‡ä»¶ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰
   */
  public static async detectDuplicateMedia(mediaList: any[]): Promise<any[]> {
    if (!mediaList.length) return mediaList;

    // è·å–æ‰€æœ‰æ–‡ä»¶å“ˆå¸Œ
    const fileHashes = mediaList.map(media => media.fileHash).filter(Boolean);

    if (!fileHashes.length) return mediaList;

    try {
      // æŸ¥è¯¢æ¯ä¸ªå“ˆå¸Œçš„ä½¿ç”¨æ¬¡æ•°
      const hashCounts = await prisma.fileHash.findMany({
        where: {
          hash: {
            in: fileHashes
          }
        },
        select: {
          hash: true,
          uploadCount: true,
        }
      });

      // åˆ›å»ºå“ˆå¸Œè®¡æ•°æ˜ å°„
      const hashCountMap = new Map<string, number>();
      hashCounts.forEach(item => {
        // ä½¿ç”¨ uploadCount
        const count = item.uploadCount || 0;
        hashCountMap.set(item.hash, count);
      });

      // æ ‡è®°é‡å¤æ–‡ä»¶
      return mediaList.map(media => ({
        ...media,
        isDuplicate: (hashCountMap.get(media.fileHash) || 1) > 1,
        duplicateCount: hashCountMap.get(media.fileHash) || 1
      }));

    } catch (error) {
      console.error('æ£€æµ‹é‡å¤æ–‡ä»¶å¤±è´¥:', error);
      // å‘ç”Ÿé”™è¯¯æ—¶è¿”å›åŸå§‹æ•°æ®
      return mediaList;
    }
  }

  /**
   * æ¸…ç†æ— æ•ˆçš„é‡å¤æ–‡ä»¶è®°å½•
   */
  public static async cleanupInvalidRecords(): Promise<{
    cleaned: number;
    errors: string[];
  }> {
    const result = {
      cleaned: 0,
      errors: [] as string[],
    };

    try {
      // æŸ¥æ‰¾æ‰€æœ‰é‡å¤æ–‡ä»¶è®°å½•
      const allRecords = await prisma.fileHash.findMany();

      for (const record of allRecords) {
        try {
          // æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä»ç„¶å­˜åœ¨äºPostMediaè¡¨ä¸­
          const mediaExists = await prisma.postMedia.findFirst({
            where: { fileHash: record.hash },
          });

          if (!mediaExists) {
            // å¦‚æœæ²¡æœ‰å…³è”çš„åª’ä½“è®°å½•ï¼Œåˆ é™¤å“ˆå¸Œè®°å½•
            await prisma.fileHash.delete({
              where: { id: record.id },
            });
            result.cleaned++;
            console.log(`ğŸ§¹ æ¸…ç†æ— æ•ˆè®°å½•: ${record.filename}`);
          }
        } catch (error) {
          const errorMsg = `æ¸…ç†è®°å½• ${record.id} å¤±è´¥: ${error}`;
          result.errors.push(errorMsg);
          console.error(errorMsg);
        }
      }

      console.log(`âœ… æ¸…ç†å®Œæˆ: åˆ é™¤äº† ${result.cleaned} ä¸ªæ— æ•ˆè®°å½•`);
      return result;
    } catch (error) {
      console.error('æ¸…ç†æ— æ•ˆè®°å½•æ—¶å‡ºé”™:', error);
      result.errors.push(`æ¸…ç†è¿‡ç¨‹å¤±è´¥: ${error}`);
      return result;
    }
  }
}
